<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>python_medata.acm_scraper API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>python_medata.acm_scraper</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import requests
from bs4 import BeautifulSoup
import re


class Category():
    &#34;&#34;&#34;Class to store one Categorie found in the paper

    Returns:
        None: simply there to store more information 
    &#34;&#34;&#34;
    numbers = []
    name = &#34;&#34;
    has_children = True
    children = []
    
    def __init__(self, numbers: list, name: str):
        self.numbers = numbers
        self.name = name

    def to_dict(self):
        return {
            &#34;name&#34;: this.name,
            &#34;numbers&#34;: this.numbers
        }


def main():
    &#34;&#34;&#34;for testing purposes
    &#34;&#34;&#34;

    url = &#34;https://dl.acm.org/doi/10.1145/3230543.3230575&#34;
    url = &#34;https://dl.acm.org/doi/10.1145/3432935&#34;
    binder_url = &#34;https://dl.acm.org/action/showBinder?binderCode=READINGLIST-a74de539-6fb8-4617-8b68-66e52f59c64a&#34;
    
    soup = get_soup(url)
    leaf_cats = get_categories(soup)
    facts_soup = get_facts_soup(soup)

    print(get_title(soup))


    authors = get_authors(facts_soup)
    print(&#34;------------------&#34;)
    for author in authors:
        name_from_profile(author)

    authors_string = &#34;,&#34;.join(authors)
    print(&#34;,&#34;.join(authors))
    print(authors_string.split(&#34;,&#34;))


def get_urls_from_binder(url):
    soup = get_soup(url)
    print(soup)


def get_leaf_categories(url):
    &#34;&#34;&#34; Get all leaf Categories as a list of Strings

    Args:
        url (str): url of the paper on ACM. Url is not checked

    Returns:
        leaf_list (list of str): List of Strings with the names of all Leaf categories
    &#34;&#34;&#34;
    soup = get_soup(url)
    leaf_list = get_categories(soup)
    return leaf_list


def get_soup(url):
    &#34;&#34;&#34;Return a soup object

    Args:
        url (String): URL of the page as String

    Returns:
        BeautifulSoup: soup object
    &#34;&#34;&#34;
    html_string = requests.get(url).text
    soup = BeautifulSoup(html_string, &#34;lxml&#34;)
    return soup


def get_facts_soup(soup:BeautifulSoup):
    return soup.find(class_=&#34;citation&#34;)


def get_all_infos(soup):
    #sub div from soup
    facts = soup.find(class_=&#34;citation&#34;)
    print(f&#34;there are {len(authors_info)} authors in this paper&#34;)


def get_title(facts_soup):
    &#34;&#34;&#34;Get the title of the Paper

    Args:
        facts_soup (BeautifulSoup soup): sub soup of the complete page

    As the Informations appear multiple times on the webpage we need to split the complete soup into sub-soups
    This should also improve the performance - at least by a little :)

    Returns:
        String: title of the page
    &#34;&#34;&#34;
    title = facts_soup.find(&#34;h1&#34;, class_=&#34;citation__title&#34;).text
    return title

   
def get_authors(facts_soup):
    &#34;&#34;&#34;Returns a list of the links to the authors profiles

    Args:
        facts_soup (BeautifulSoup soup): sub soup

    Returns:
        list: list of links to authors profiles, better to track as names can be doubled
    &#34;&#34;&#34;
    authors_info = facts_soup.find_all(class_=&#34;loa__item&#34;)
    #finds all classes which contain the authors information
    authors_profile_list = []
    for author in authors_info:
        # #print(f&#34;{author}\n\n\n&#34;)
        # print(author.find(&#34;a&#34;).get(&#34;title&#34;)) #Name of the Author
        # print(author.find(class_=&#34;author-info__body&#34;).find(&#34;p&#34;).text) #Institute he/she is working at
        try:
            authors_profile_link = author.find(class_=&#34;author-info&#34;).find(&#34;a&#34;).get(&#34;href&#34;)
            authors_profile_link = &#34;https://dl.acm.org&#34; + authors_profile_link
            
            authors_profile_list.append(authors_profile_link)
            # print(authors_profile_link) #link to their profile
        except AttributeError as ae:
            print(f&#34;AttributeError: {ae}&#34;)

        #print(name_from_profile(author.find(class_=&#34;author-info&#34;).find(&#34;a&#34;).get(&#34;href&#34;)))          
    return authors_profile_list
    

def name_from_profile(link):
    &#34;&#34;&#34;get the Authors name from his/her profile

    Args:
        link (string): link to the authors profile

    Returns:
        string: name of the Author
    &#34;&#34;&#34;
    if &#34;dl.acm.org&#34; in link:
        url = link
    else:
        url = &#34;https://dl.acm.org&#34;+link
    # print(url)

    if r&#34;/author/&#34; in url:
        name = re.sub(r&#34;[\W\w]*\/author\/&#34;, &#34;&#34;, url)
        n = re.split(&#34;,&#34;,name)
        n[0], n[1] = n[1],n[0]
        for i in n:
            i.strip()
        name = &#34; &#34;.join(n)
    else:
        #at recently published papers it may happen that the profile of the author is not yet linked to the paper
        html = requests.get(url).text
        profile = BeautifulSoup(html, &#34;lxml&#34;)
        #print(f&#34;scraper.name_from_profile for this url: {url}&#34;)
        name = profile.find(class_=&#34;colored-block item-meta profile-meta&#34;).find(&#34;h2&#34;).text.replace(&#34;  &#34;,&#34; &#34;).strip()

    return name
    

def get_paper_id(link):
    &#34;&#34;&#34;Paper Id and conference Id - probably unnecessary

    Args:
        link (string): link to the paper

    Returns:
        string: conferenceId.paperId
    &#34;&#34;&#34;
    id = re.sub(r&#34;https:\/\/dl\.acm\.org\/doi\/[\d*\.\d*]+\/&#34;, &#34;&#34;, link)
    return id


def get_conference(link):
    &#34;&#34;&#34;Get the name of the conference by the link of the paper

    Args:
        link (string): link of the paper    

    Returns:
        string : name of the conference the paper was published under
    &#34;&#34;&#34;


    #first you have to remove the paperid from the link to get the conference link
    if re.match(r&#34;[\W\w]*\/\d{4,}.\d{4,}&#34;, link):
        conf_link = re.sub(r&#39;\.\d{5,}&#39;, &#34;&#34;, link)
        #print(conf_link)
        html = requests.get(conf_link).text
        soup = BeautifulSoup(html, &#34;lxml&#34;)

        conference = soup.find(class_=&#34;left-bordered-title&#34;).text
    else:
        #TODO return Journals name it was published under
        conference = &#34;Not published with a Conference&#34;
    return conference


def get_categories(soup):
    &#34;&#34;&#34;Get a list of the leaf Categories

    Args:
        soup (BeautifulSoup): the soup of the complete website

    for an explanation how the children categories are identified have a look at the comments for 
    get_infos_of_cat_link(link) there is a more in-depth explanation of how the links to the categories are build

    Returns:
        list (String): List of the names of the leaf categories
    &#34;&#34;&#34;
    organizational_chart = soup.find(&#34;ol&#34;, class_=&#34;rlist organizational-chart&#34;)     
    categories_container = organizational_chart.find_all(&#34;a&#34;)
    #print(len(categories_container))
    categories_text = []
    categories_list = []
    leaf_categories_list = []

    # creates Categorie objects and appends them to a list
    for categorie in categories_container:
        try:
            name = categorie.text 
            numbers = get_infos_of_cat_link(categorie.get(&#34;href&#34;))
            cat = Category(numbers,name)
            categories_list.append(cat)

        except Exception as e:
             print(e)   

    # checks if the categorie has children or not
    for categorie in categories_list:
        
        rest_cats = [cat.numbers for cat in categories_list if not cat == categorie]
        #rest_cats is a list of the remaining categories
        rest_numbers = [nr for sublist in rest_cats for nr in sublist]
        # list comprehension puts all numbers in one list
        last_number = categorie.numbers[-1]

        if last_number not in rest_numbers:
            categorie.has_children = False
        
    # appends leaf categories to a list
    for categorie in categories_list:
        if categorie.has_children == False:
            leaf_categories_list.append(categorie.name)


    return leaf_categories_list


def get_infos_of_cat_link(link):
    &#34;&#34;&#34;get all category numbers from a given link

    Args:
        link (link to a (sub-) category): this link contains all parent categories numbers

    a link to a category is build up like this:
    https://dl.acm.org/topic/ccs2012/10003120.10003138.10003141?SeriesKey=imwut&amp;expand=all

    first we remove everything after the ?

    https://dl.acm.org/topic/ccs2012/10003120.10003138.10003141

    then everthing before the last /

    10003120.10003138.10003141

    these 3 numbers indicate that this category has 2 parent categories
    these 3 numbers are then split by the . and are put into a list which is returned

    If a category number is later found more then once you can be sure that this is NOT a leaf category.
    This is because the link to the first parent category looks like this:

    https://dl.acm.org/topic/ccs2012/10003120.10003138

    

    Returns:
        list(int): List of Integers to all the parent categories
    &#34;&#34;&#34;
    #return an ordered list with all category and subcategories Numbers
    categories_numbers = []
    cat_string = re.sub(r&#34;\?[\w*\W*]*&#34;,&#34;&#34;, link)
    # removes everything after the ?
    cat_string = re.sub(r&#34;[\w*\W*]*\/&#34;, &#34;&#34;, cat_string)
    # removes everything before the last /
    categories_numbers = re.split(r&#34;\.&#34;, cat_string)
    # splits the numbery by the .
    return categories_numbers

if __name__ == &#34;__main__&#34;:
    main()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="python_medata.acm_scraper.get_all_infos"><code class="name flex">
<span>def <span class="ident">get_all_infos</span></span>(<span>soup)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_all_infos(soup):
    #sub div from soup
    facts = soup.find(class_=&#34;citation&#34;)
    print(f&#34;there are {len(authors_info)} authors in this paper&#34;)</code></pre>
</details>
</dd>
<dt id="python_medata.acm_scraper.get_authors"><code class="name flex">
<span>def <span class="ident">get_authors</span></span>(<span>facts_soup)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a list of the links to the authors profiles</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>facts_soup</code></strong> :&ensp;<code>BeautifulSoup soup</code></dt>
<dd>sub soup</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code></dt>
<dd>list of links to authors profiles, better to track as names can be doubled</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_authors(facts_soup):
    &#34;&#34;&#34;Returns a list of the links to the authors profiles

    Args:
        facts_soup (BeautifulSoup soup): sub soup

    Returns:
        list: list of links to authors profiles, better to track as names can be doubled
    &#34;&#34;&#34;
    authors_info = facts_soup.find_all(class_=&#34;loa__item&#34;)
    #finds all classes which contain the authors information
    authors_profile_list = []
    for author in authors_info:
        # #print(f&#34;{author}\n\n\n&#34;)
        # print(author.find(&#34;a&#34;).get(&#34;title&#34;)) #Name of the Author
        # print(author.find(class_=&#34;author-info__body&#34;).find(&#34;p&#34;).text) #Institute he/she is working at
        try:
            authors_profile_link = author.find(class_=&#34;author-info&#34;).find(&#34;a&#34;).get(&#34;href&#34;)
            authors_profile_link = &#34;https://dl.acm.org&#34; + authors_profile_link
            
            authors_profile_list.append(authors_profile_link)
            # print(authors_profile_link) #link to their profile
        except AttributeError as ae:
            print(f&#34;AttributeError: {ae}&#34;)

        #print(name_from_profile(author.find(class_=&#34;author-info&#34;).find(&#34;a&#34;).get(&#34;href&#34;)))          
    return authors_profile_list</code></pre>
</details>
</dd>
<dt id="python_medata.acm_scraper.get_categories"><code class="name flex">
<span>def <span class="ident">get_categories</span></span>(<span>soup)</span>
</code></dt>
<dd>
<div class="desc"><p>Get a list of the leaf Categories</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>soup</code></strong> :&ensp;<code>BeautifulSoup</code></dt>
<dd>the soup of the complete website</dd>
</dl>
<p>for an explanation how the children categories are identified have a look at the comments for
get_infos_of_cat_link(link) there is a more in-depth explanation of how the links to the categories are build</p>
<h2 id="returns">Returns</h2>
<p>list (String): List of the names of the leaf categories</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_categories(soup):
    &#34;&#34;&#34;Get a list of the leaf Categories

    Args:
        soup (BeautifulSoup): the soup of the complete website

    for an explanation how the children categories are identified have a look at the comments for 
    get_infos_of_cat_link(link) there is a more in-depth explanation of how the links to the categories are build

    Returns:
        list (String): List of the names of the leaf categories
    &#34;&#34;&#34;
    organizational_chart = soup.find(&#34;ol&#34;, class_=&#34;rlist organizational-chart&#34;)     
    categories_container = organizational_chart.find_all(&#34;a&#34;)
    #print(len(categories_container))
    categories_text = []
    categories_list = []
    leaf_categories_list = []

    # creates Categorie objects and appends them to a list
    for categorie in categories_container:
        try:
            name = categorie.text 
            numbers = get_infos_of_cat_link(categorie.get(&#34;href&#34;))
            cat = Category(numbers,name)
            categories_list.append(cat)

        except Exception as e:
             print(e)   

    # checks if the categorie has children or not
    for categorie in categories_list:
        
        rest_cats = [cat.numbers for cat in categories_list if not cat == categorie]
        #rest_cats is a list of the remaining categories
        rest_numbers = [nr for sublist in rest_cats for nr in sublist]
        # list comprehension puts all numbers in one list
        last_number = categorie.numbers[-1]

        if last_number not in rest_numbers:
            categorie.has_children = False
        
    # appends leaf categories to a list
    for categorie in categories_list:
        if categorie.has_children == False:
            leaf_categories_list.append(categorie.name)


    return leaf_categories_list</code></pre>
</details>
</dd>
<dt id="python_medata.acm_scraper.get_conference"><code class="name flex">
<span>def <span class="ident">get_conference</span></span>(<span>link)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the name of the conference by the link of the paper</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>link</code></strong> :&ensp;<code>string</code></dt>
<dd>link of the paper
</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>string </code></dt>
<dd>name of the conference the paper was published under</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_conference(link):
    &#34;&#34;&#34;Get the name of the conference by the link of the paper

    Args:
        link (string): link of the paper    

    Returns:
        string : name of the conference the paper was published under
    &#34;&#34;&#34;


    #first you have to remove the paperid from the link to get the conference link
    if re.match(r&#34;[\W\w]*\/\d{4,}.\d{4,}&#34;, link):
        conf_link = re.sub(r&#39;\.\d{5,}&#39;, &#34;&#34;, link)
        #print(conf_link)
        html = requests.get(conf_link).text
        soup = BeautifulSoup(html, &#34;lxml&#34;)

        conference = soup.find(class_=&#34;left-bordered-title&#34;).text
    else:
        #TODO return Journals name it was published under
        conference = &#34;Not published with a Conference&#34;
    return conference</code></pre>
</details>
</dd>
<dt id="python_medata.acm_scraper.get_facts_soup"><code class="name flex">
<span>def <span class="ident">get_facts_soup</span></span>(<span>soup: bs4.BeautifulSoup)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_facts_soup(soup:BeautifulSoup):
    return soup.find(class_=&#34;citation&#34;)</code></pre>
</details>
</dd>
<dt id="python_medata.acm_scraper.get_infos_of_cat_link"><code class="name flex">
<span>def <span class="ident">get_infos_of_cat_link</span></span>(<span>link)</span>
</code></dt>
<dd>
<div class="desc"><p>get all category numbers from a given link</p>
<h2 id="args">Args</h2>
<p>link (link to a (sub-) category): this link contains all parent categories numbers
a link to a category is build up like this:
<a href="https://dl.acm.org/topic/ccs2012/10003120.10003138.10003141?SeriesKey=imwut&amp;expand=all">https://dl.acm.org/topic/ccs2012/10003120.10003138.10003141?SeriesKey=imwut&amp;expand=all</a></p>
<p>first we remove everything after the ?</p>
<p><a href="https://dl.acm.org/topic/ccs2012/10003120.10003138.10003141">https://dl.acm.org/topic/ccs2012/10003120.10003138.10003141</a></p>
<p>then everthing before the last /</p>
<p>10003120.10003138.10003141</p>
<p>these 3 numbers indicate that this category has 2 parent categories
these 3 numbers are then split by the . and are put into a list which is returned</p>
<p>If a category number is later found more then once you can be sure that this is NOT a leaf category.
This is because the link to the first parent category looks like this:</p>
<p><a href="https://dl.acm.org/topic/ccs2012/10003120.10003138">https://dl.acm.org/topic/ccs2012/10003120.10003138</a></p>
<h2 id="returns">Returns</h2>
<p>list(int): List of Integers to all the parent categories</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_infos_of_cat_link(link):
    &#34;&#34;&#34;get all category numbers from a given link

    Args:
        link (link to a (sub-) category): this link contains all parent categories numbers

    a link to a category is build up like this:
    https://dl.acm.org/topic/ccs2012/10003120.10003138.10003141?SeriesKey=imwut&amp;expand=all

    first we remove everything after the ?

    https://dl.acm.org/topic/ccs2012/10003120.10003138.10003141

    then everthing before the last /

    10003120.10003138.10003141

    these 3 numbers indicate that this category has 2 parent categories
    these 3 numbers are then split by the . and are put into a list which is returned

    If a category number is later found more then once you can be sure that this is NOT a leaf category.
    This is because the link to the first parent category looks like this:

    https://dl.acm.org/topic/ccs2012/10003120.10003138

    

    Returns:
        list(int): List of Integers to all the parent categories
    &#34;&#34;&#34;
    #return an ordered list with all category and subcategories Numbers
    categories_numbers = []
    cat_string = re.sub(r&#34;\?[\w*\W*]*&#34;,&#34;&#34;, link)
    # removes everything after the ?
    cat_string = re.sub(r&#34;[\w*\W*]*\/&#34;, &#34;&#34;, cat_string)
    # removes everything before the last /
    categories_numbers = re.split(r&#34;\.&#34;, cat_string)
    # splits the numbery by the .
    return categories_numbers</code></pre>
</details>
</dd>
<dt id="python_medata.acm_scraper.get_leaf_categories"><code class="name flex">
<span>def <span class="ident">get_leaf_categories</span></span>(<span>url)</span>
</code></dt>
<dd>
<div class="desc"><p>Get all leaf Categories as a list of Strings</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>url</code></strong> :&ensp;<code>str</code></dt>
<dd>url of the paper on ACM. Url is not checked</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>leaf_list (list of str): List of Strings with the names of all Leaf categories</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_leaf_categories(url):
    &#34;&#34;&#34; Get all leaf Categories as a list of Strings

    Args:
        url (str): url of the paper on ACM. Url is not checked

    Returns:
        leaf_list (list of str): List of Strings with the names of all Leaf categories
    &#34;&#34;&#34;
    soup = get_soup(url)
    leaf_list = get_categories(soup)
    return leaf_list</code></pre>
</details>
</dd>
<dt id="python_medata.acm_scraper.get_paper_id"><code class="name flex">
<span>def <span class="ident">get_paper_id</span></span>(<span>link)</span>
</code></dt>
<dd>
<div class="desc"><p>Paper Id and conference Id - probably unnecessary</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>link</code></strong> :&ensp;<code>string</code></dt>
<dd>link to the paper</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>string</code></dt>
<dd>conferenceId.paperId</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_paper_id(link):
    &#34;&#34;&#34;Paper Id and conference Id - probably unnecessary

    Args:
        link (string): link to the paper

    Returns:
        string: conferenceId.paperId
    &#34;&#34;&#34;
    id = re.sub(r&#34;https:\/\/dl\.acm\.org\/doi\/[\d*\.\d*]+\/&#34;, &#34;&#34;, link)
    return id</code></pre>
</details>
</dd>
<dt id="python_medata.acm_scraper.get_soup"><code class="name flex">
<span>def <span class="ident">get_soup</span></span>(<span>url)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a soup object</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>url</code></strong> :&ensp;<code>String</code></dt>
<dd>URL of the page as String</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>BeautifulSoup</code></dt>
<dd>soup object</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_soup(url):
    &#34;&#34;&#34;Return a soup object

    Args:
        url (String): URL of the page as String

    Returns:
        BeautifulSoup: soup object
    &#34;&#34;&#34;
    html_string = requests.get(url).text
    soup = BeautifulSoup(html_string, &#34;lxml&#34;)
    return soup</code></pre>
</details>
</dd>
<dt id="python_medata.acm_scraper.get_title"><code class="name flex">
<span>def <span class="ident">get_title</span></span>(<span>facts_soup)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the title of the Paper</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>facts_soup</code></strong> :&ensp;<code>BeautifulSoup soup</code></dt>
<dd>sub soup of the complete page</dd>
</dl>
<p>As the Informations appear multiple times on the webpage we need to split the complete soup into sub-soups
This should also improve the performance - at least by a little :)</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>String</code></dt>
<dd>title of the page</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_title(facts_soup):
    &#34;&#34;&#34;Get the title of the Paper

    Args:
        facts_soup (BeautifulSoup soup): sub soup of the complete page

    As the Informations appear multiple times on the webpage we need to split the complete soup into sub-soups
    This should also improve the performance - at least by a little :)

    Returns:
        String: title of the page
    &#34;&#34;&#34;
    title = facts_soup.find(&#34;h1&#34;, class_=&#34;citation__title&#34;).text
    return title</code></pre>
</details>
</dd>
<dt id="python_medata.acm_scraper.get_urls_from_binder"><code class="name flex">
<span>def <span class="ident">get_urls_from_binder</span></span>(<span>url)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_urls_from_binder(url):
    soup = get_soup(url)
    print(soup)</code></pre>
</details>
</dd>
<dt id="python_medata.acm_scraper.main"><code class="name flex">
<span>def <span class="ident">main</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>for testing purposes</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def main():
    &#34;&#34;&#34;for testing purposes
    &#34;&#34;&#34;

    url = &#34;https://dl.acm.org/doi/10.1145/3230543.3230575&#34;
    url = &#34;https://dl.acm.org/doi/10.1145/3432935&#34;
    binder_url = &#34;https://dl.acm.org/action/showBinder?binderCode=READINGLIST-a74de539-6fb8-4617-8b68-66e52f59c64a&#34;
    
    soup = get_soup(url)
    leaf_cats = get_categories(soup)
    facts_soup = get_facts_soup(soup)

    print(get_title(soup))


    authors = get_authors(facts_soup)
    print(&#34;------------------&#34;)
    for author in authors:
        name_from_profile(author)

    authors_string = &#34;,&#34;.join(authors)
    print(&#34;,&#34;.join(authors))
    print(authors_string.split(&#34;,&#34;))</code></pre>
</details>
</dd>
<dt id="python_medata.acm_scraper.name_from_profile"><code class="name flex">
<span>def <span class="ident">name_from_profile</span></span>(<span>link)</span>
</code></dt>
<dd>
<div class="desc"><p>get the Authors name from his/her profile</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>link</code></strong> :&ensp;<code>string</code></dt>
<dd>link to the authors profile</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>string</code></dt>
<dd>name of the Author</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def name_from_profile(link):
    &#34;&#34;&#34;get the Authors name from his/her profile

    Args:
        link (string): link to the authors profile

    Returns:
        string: name of the Author
    &#34;&#34;&#34;
    if &#34;dl.acm.org&#34; in link:
        url = link
    else:
        url = &#34;https://dl.acm.org&#34;+link
    # print(url)

    if r&#34;/author/&#34; in url:
        name = re.sub(r&#34;[\W\w]*\/author\/&#34;, &#34;&#34;, url)
        n = re.split(&#34;,&#34;,name)
        n[0], n[1] = n[1],n[0]
        for i in n:
            i.strip()
        name = &#34; &#34;.join(n)
    else:
        #at recently published papers it may happen that the profile of the author is not yet linked to the paper
        html = requests.get(url).text
        profile = BeautifulSoup(html, &#34;lxml&#34;)
        #print(f&#34;scraper.name_from_profile for this url: {url}&#34;)
        name = profile.find(class_=&#34;colored-block item-meta profile-meta&#34;).find(&#34;h2&#34;).text.replace(&#34;  &#34;,&#34; &#34;).strip()

    return name</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="python_medata.acm_scraper.Category"><code class="flex name class">
<span>class <span class="ident">Category</span></span>
<span>(</span><span>numbers: list, name: str)</span>
</code></dt>
<dd>
<div class="desc"><p>Class to store one Categorie found in the paper</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>simply there to store more information</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Category():
    &#34;&#34;&#34;Class to store one Categorie found in the paper

    Returns:
        None: simply there to store more information 
    &#34;&#34;&#34;
    numbers = []
    name = &#34;&#34;
    has_children = True
    children = []
    
    def __init__(self, numbers: list, name: str):
        self.numbers = numbers
        self.name = name

    def to_dict(self):
        return {
            &#34;name&#34;: this.name,
            &#34;numbers&#34;: this.numbers
        }</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="python_medata.acm_scraper.Category.children"><code class="name">var <span class="ident">children</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="python_medata.acm_scraper.Category.has_children"><code class="name">var <span class="ident">has_children</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="python_medata.acm_scraper.Category.name"><code class="name">var <span class="ident">name</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="python_medata.acm_scraper.Category.numbers"><code class="name">var <span class="ident">numbers</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="python_medata.acm_scraper.Category.to_dict"><code class="name flex">
<span>def <span class="ident">to_dict</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_dict(self):
    return {
        &#34;name&#34;: this.name,
        &#34;numbers&#34;: this.numbers
    }</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="python_medata" href="index.html">python_medata</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="python_medata.acm_scraper.get_all_infos" href="#python_medata.acm_scraper.get_all_infos">get_all_infos</a></code></li>
<li><code><a title="python_medata.acm_scraper.get_authors" href="#python_medata.acm_scraper.get_authors">get_authors</a></code></li>
<li><code><a title="python_medata.acm_scraper.get_categories" href="#python_medata.acm_scraper.get_categories">get_categories</a></code></li>
<li><code><a title="python_medata.acm_scraper.get_conference" href="#python_medata.acm_scraper.get_conference">get_conference</a></code></li>
<li><code><a title="python_medata.acm_scraper.get_facts_soup" href="#python_medata.acm_scraper.get_facts_soup">get_facts_soup</a></code></li>
<li><code><a title="python_medata.acm_scraper.get_infos_of_cat_link" href="#python_medata.acm_scraper.get_infos_of_cat_link">get_infos_of_cat_link</a></code></li>
<li><code><a title="python_medata.acm_scraper.get_leaf_categories" href="#python_medata.acm_scraper.get_leaf_categories">get_leaf_categories</a></code></li>
<li><code><a title="python_medata.acm_scraper.get_paper_id" href="#python_medata.acm_scraper.get_paper_id">get_paper_id</a></code></li>
<li><code><a title="python_medata.acm_scraper.get_soup" href="#python_medata.acm_scraper.get_soup">get_soup</a></code></li>
<li><code><a title="python_medata.acm_scraper.get_title" href="#python_medata.acm_scraper.get_title">get_title</a></code></li>
<li><code><a title="python_medata.acm_scraper.get_urls_from_binder" href="#python_medata.acm_scraper.get_urls_from_binder">get_urls_from_binder</a></code></li>
<li><code><a title="python_medata.acm_scraper.main" href="#python_medata.acm_scraper.main">main</a></code></li>
<li><code><a title="python_medata.acm_scraper.name_from_profile" href="#python_medata.acm_scraper.name_from_profile">name_from_profile</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="python_medata.acm_scraper.Category" href="#python_medata.acm_scraper.Category">Category</a></code></h4>
<ul class="">
<li><code><a title="python_medata.acm_scraper.Category.children" href="#python_medata.acm_scraper.Category.children">children</a></code></li>
<li><code><a title="python_medata.acm_scraper.Category.has_children" href="#python_medata.acm_scraper.Category.has_children">has_children</a></code></li>
<li><code><a title="python_medata.acm_scraper.Category.name" href="#python_medata.acm_scraper.Category.name">name</a></code></li>
<li><code><a title="python_medata.acm_scraper.Category.numbers" href="#python_medata.acm_scraper.Category.numbers">numbers</a></code></li>
<li><code><a title="python_medata.acm_scraper.Category.to_dict" href="#python_medata.acm_scraper.Category.to_dict">to_dict</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>